{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cmsScrape.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kabish01/webScrape/blob/main/cmsScrape.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrOK-SNWpWIC"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNG2njWGt9sq"
      },
      "source": [
        "# with open('simple.html') as html_file:\n",
        "#   soup = BeautifulSoup(html_file, 'lxml')\n",
        "\n",
        "# print(soup)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koJOGYeOuPk4"
      },
      "source": [
        "html_doc = \"\"\"\n",
        "<!doctype html>\n",
        "<html class=\"no-js\" lang=\"\">\n",
        "    <head>\n",
        "        <title>Test - A Sample Website</title>\n",
        "        <meta charset=\"utf-8\">\n",
        "        <link rel=\"stylesheet\" href=\"css/normalize.css\">\n",
        "        <link rel=\"stylesheet\" href=\"css/main.css\">\n",
        "    </head>\n",
        "    <body>\n",
        "        <h1 id='site_title'>Test Website</h1>\n",
        "        <hr></hr>\n",
        "        <div class=\"article\">\n",
        "            <h2><a href=\"article_1.html\">Article 1 Headline</a></h2>\n",
        "            <p>This is a summary of article 1</p>\n",
        "        </div>\n",
        "        <hr></hr>\n",
        "        <div class=\"article\">\n",
        "            <h2><a href=\"article_2.html\">Article 2 Headline</a></h2>\n",
        "            <p>This is a summary of article 2</p>\n",
        "        </div>\n",
        "        <hr></hr>\n",
        "\n",
        "        <div class='footer'>\n",
        "            <p>Footer Information</p>\n",
        "        </div>\n",
        "\n",
        "        <script src=\"js/vendor/modernizr-3.5.0.min.js\"></script>\n",
        "        <script src=\"js/plugins.js\"></script>\n",
        "        <script src=\"js/main.js\"></script>\n",
        "    </body>\n",
        "</html>\n",
        "\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vt6N8WLEveKW"
      },
      "source": [
        "with open('simple.html', 'w') as f:\n",
        "  f.write(html_doc)\n",
        "  f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfezBCdPvwQG"
      },
      "source": [
        "with open('simple.html') as html_file:\n",
        "  soup = BeautifulSoup(html_file, 'lxml')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvKR5gV1wOBq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "outputId": "3c2e38a4-41df-4c74-a458-68cdd725f02d"
      },
      "source": [
        "print(soup)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<!DOCTYPE html>\n",
            "<html class=\"no-js\" lang=\"\">\n",
            "<head>\n",
            "<title>Test - A Sample Website</title>\n",
            "<meta charset=\"utf-8\"/>\n",
            "<link href=\"css/normalize.css\" rel=\"stylesheet\"/>\n",
            "<link href=\"css/main.css\" rel=\"stylesheet\"/>\n",
            "</head>\n",
            "<body>\n",
            "<h1 id=\"site_title\">Test Website</h1>\n",
            "<hr/>\n",
            "<div class=\"article\">\n",
            "<h2><a href=\"article_1.html\">Article 1 Headline</a></h2>\n",
            "<p>This is a summary of article 1</p>\n",
            "</div>\n",
            "<hr/>\n",
            "<div class=\"article\">\n",
            "<h2><a href=\"article_2.html\">Article 2 Headline</a></h2>\n",
            "<p>This is a summary of article 2</p>\n",
            "</div>\n",
            "<hr/>\n",
            "<div class=\"footer\">\n",
            "<p>Footer Information</p>\n",
            "</div>\n",
            "<script src=\"js/vendor/modernizr-3.5.0.min.js\"></script>\n",
            "<script src=\"js/plugins.js\"></script>\n",
            "<script src=\"js/main.js\"></script>\n",
            "</body>\n",
            "</html>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYKTKbYCwSv1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 944
        },
        "outputId": "5198affc-d638-4815-fcec-d8f8ea59b3a5"
      },
      "source": [
        "print(soup.prettify())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<!DOCTYPE html>\n",
            "<html class=\"no-js\" lang=\"\">\n",
            " <head>\n",
            "  <title>\n",
            "   Test - A Sample Website\n",
            "  </title>\n",
            "  <meta charset=\"utf-8\"/>\n",
            "  <link href=\"css/normalize.css\" rel=\"stylesheet\"/>\n",
            "  <link href=\"css/main.css\" rel=\"stylesheet\"/>\n",
            " </head>\n",
            " <body>\n",
            "  <h1 id=\"site_title\">\n",
            "   Test Website\n",
            "  </h1>\n",
            "  <hr/>\n",
            "  <div class=\"article\">\n",
            "   <h2>\n",
            "    <a href=\"article_1.html\">\n",
            "     Article 1 Headline\n",
            "    </a>\n",
            "   </h2>\n",
            "   <p>\n",
            "    This is a summary of article 1\n",
            "   </p>\n",
            "  </div>\n",
            "  <hr/>\n",
            "  <div class=\"article\">\n",
            "   <h2>\n",
            "    <a href=\"article_2.html\">\n",
            "     Article 2 Headline\n",
            "    </a>\n",
            "   </h2>\n",
            "   <p>\n",
            "    This is a summary of article 2\n",
            "   </p>\n",
            "  </div>\n",
            "  <hr/>\n",
            "  <div class=\"footer\">\n",
            "   <p>\n",
            "    Footer Information\n",
            "   </p>\n",
            "  </div>\n",
            "  <script src=\"js/vendor/modernizr-3.5.0.min.js\">\n",
            "  </script>\n",
            "  <script src=\"js/plugins.js\">\n",
            "  </script>\n",
            "  <script src=\"js/main.js\">\n",
            "  </script>\n",
            " </body>\n",
            "</html>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZmistGSwlbE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "74e89067-7a2c-483e-fcff-b585f4757c8e"
      },
      "source": [
        "match = soup.title \n",
        "print(match, '\\n')\n",
        "match = soup.title.text\n",
        "print(match, '\\n')\n",
        "match = soup.div\n",
        "print(match)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<title>Test - A Sample Website</title> \n",
            "\n",
            "Test - A Sample Website \n",
            "\n",
            "<div class=\"article\">\n",
            "<h2><a href=\"article_1.html\">Article 1 Headline</a></h2>\n",
            "<p>This is a summary of article 1</p>\n",
            "</div>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H44Zo48z3eYz"
      },
      "source": [
        "Searching for a tag by accessing it like an attribute (like soup.title.text), will get the first title tag on the page.\n",
        "\n",
        " But we might want other tags on the page besides the first tag.\n",
        " \n",
        " The 'find()' method allows to do something similar and it also allows us to pass in some arguments so that we can find the exact tag that we're looking for.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Llq3eVVvxvFd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "33b54a4e-93cc-4481-f3dd-287e29315f97"
      },
      "source": [
        "match = soup.find('div')\n",
        "print(match)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<div class=\"article\">\n",
            "<h2><a href=\"article_1.html\">Article 1 Headline</a></h2>\n",
            "<p>This is a summary of article 1</p>\n",
            "</div>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gljdMe2NA24Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "6c645fec-82ef-4b97-d583-0f670f3f9571"
      },
      "source": [
        "match = soup.find('div', class_='footer')   # We can access any tag we want . Here we use \"class_\" because \"class\" is a special keyword in python.\n",
        "print(match)\n",
        "# Now we are not getting the first div on the page, we are getting the div with class \"footer\"."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<div class=\"footer\">\n",
            "<p>Footer Information</p>\n",
            "</div>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BWq5ZpxBJ0J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "c88f8f4c-16f1-411b-a28f-a44352c5c023"
      },
      "source": [
        " # Let's say we want to get multiple things from a page. A good way to start is to get the one from what we want.\n",
        " # For eg:\n",
        " article = soup.find('div', class_='article')\n",
        " print(article)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<div class=\"article\">\n",
            "<h2><a href=\"article_1.html\">Article 1 Headline</a></h2>\n",
            "<p>This is a summary of article 1</p>\n",
            "</div>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qblqZOcGsNc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fe2aac8c-f8e8-4a21-eb9a-1794bc9ff3b6"
      },
      "source": [
        "headline = article.h2.a.text\n",
        "print(headline)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Article 1 Headline\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6BCWUN7GzJy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4a749ef9-3fbf-4eb0-be32-e2bbe65bbc30"
      },
      "source": [
        "summary = article.p.text\n",
        "print(summary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is a summary of article 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeMttscEHEr7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "81321729-9df3-41ba-e318-f63ca38db316"
      },
      "source": [
        "# Instead of using \"find()\" method to get the first article, we can use \"find_all()\" method to get a 'list' of all of the article tags. Or any of the tag that matches the argument.\n",
        "\n",
        "for article in soup.find_all('div', class_='article'):\n",
        "  headline = article.h2.a.text\n",
        "  print(headline)\n",
        "\n",
        "  summary = article.p.text\n",
        "  print(summary)\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Article 1 Headline\n",
            "This is a summary of article 1\n",
            "\n",
            "Article 2 Headline\n",
            "This is a summary of article 2\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8sq5_G3Iy8F"
      },
      "source": [
        "# Let's try scrapping from an actual live website:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9_YIJEkIc_v"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iTKf953JA0G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7ae43a72-048f-440c-daab-9a7911bb32b7"
      },
      "source": [
        "source = requests.get('http://coreyms.com').text\n",
        "# source = requests.get('http://coreyms.com') will get the response object. To get the source code from that response object, we use \".text\" at the end. \n",
        "soup = BeautifulSoup(source, 'lxml')\n",
        "\n",
        "csv_file = open('cms_scrape2', 'w')\n",
        "csv_writer = csv.writer(csv_file)\n",
        "csv_writer.writerow(['headline', 'summary', 'video_link'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riSZSa_0JMwW"
      },
      "source": [
        "print(soup.prettify())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9_fW3UHKH5Z"
      },
      "source": [
        "article = soup.find('article')\n",
        "print(article.prettify())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujUl9ejaR58x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a9b81c9f-1a94-457d-d237-cbb275b8bcf9"
      },
      "source": [
        "# Let's first get the headline.\n",
        "headline = article.h2.a.text\n",
        "print(headline)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python Tutorial: Zip Files – Creating and Extracting Zip Archives\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC_BX64UScKb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "5cdd5762-b4bb-4da9-9c51-4c371f9d9249"
      },
      "source": [
        "summary = article.find('div', class_='entry-content').p.text\n",
        "print(summary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "In this video, we will be learning how to create and extract zip archives. We will start by using the zipfile module, and then we will see how to do this using the shutil module. We will learn how to do this with single files and directories, as well as learning how to use gzip as well. Let’s get started…\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrreSCMQzbaa"
      },
      "source": [
        "The youtube video url is inside the <iframe> tag in our site. We need to get the Video ID from that url. So first we need to grab the URL from the iFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfMSPuUyyt_F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "3fec2187-644b-4085-cfe6-bf8e0a744c2e"
      },
      "source": [
        "vid_src = article.find('iframe', class_='youtube-player')['src'] \n",
        "# Like this we say we want the 'src' attribute of the tag vid_src = article.find('iframe', class_='youtube-player').\n",
        "print(vid_src)\n",
        "# We got the link of the embedded url.\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://www.youtube.com/embed/z0gguhEmWiY?version=3&rel=1&fs=1&autohide=2&showsearch=0&showinfo=1&iv_load_policy=1&wmode=transparent\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YO5k3wL3Uel",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "3ca18e55-d6d0-40bf-e451-f936430d9b4e"
      },
      "source": [
        "vid_id = vid_src.split('/')\n",
        "print(vid_id)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['https:', '', 'www.youtube.com', 'embed', 'z0gguhEmWiY?version=3&rel=1&fs=1&autohide=2&showsearch=0&showinfo=1&iv_load_policy=1&wmode=transparent']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri0FVw5s3sXL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "c30fb52d-706c-4a03-e88e-a3ac04ad46fc"
      },
      "source": [
        "vid_id = vid_src.split('/')[4]  # After that split method, we can say we want the index 4 for the video ID \n",
        "print(vid_id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "z0gguhEmWiY?version=3&rel=1&fs=1&autohide=2&showsearch=0&showinfo=1&iv_load_policy=1&wmode=transparent\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCmBbMft6P08"
      },
      "source": [
        "We want the 1st item (video id) from the query parameter above. The '?' indicate where the parameters for the url begin. The video id is before the '?'\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3tW5RHb40iI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a2568178-01d7-433a-b7a6-6a58c1e8797c"
      },
      "source": [
        "vid_id = vid_id.split('?')[0]\n",
        "print(vid_id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "z0gguhEmWiY\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6S45Q77l5d6u"
      },
      "source": [
        "Sometimes websites sourcecode doesn't have the information that we want in the most accessible way. Ok now we can create our own youtube link using this video id."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFO6WCpn5IY5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0846c234-8870-45ba-bdef-94db82092449"
      },
      "source": [
        "yt_link = f'https://youtube.com/watch?v={vid_id}'\n",
        "print(yt_link)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://youtube.com/watch?v=z0gguhEmWiY\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQIFqyvq8WMz"
      },
      "source": [
        "Now that we have scraped all the information from 1st article and got its information, likewise we can get information from all the articles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POckskPU7ZS-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "outputId": "9446e6be-3a9c-489f-a728-6836c1e68238"
      },
      "source": [
        "for article in soup.find_all('article'):\n",
        "\n",
        "  headline = article.h2.a.text\n",
        "  print(headline)\n",
        "\n",
        "  summary = article.find('div', class_='entry-content').p.text\n",
        "  print(summary)\n",
        "\n",
        "  try:\n",
        "    vid_src = article.find('iframe', class_='youtube-player')['src']\n",
        "    vid_id = vid_src.split('/')[4]\n",
        "    vid_id = vid_id.split('?')[0]\n",
        "\n",
        "    yt_link = f'https://youtube.com/watch?v={vid_id}'\n",
        "\n",
        "\n",
        "  except Exception as e:\n",
        "    yt_link = None\n",
        " \n",
        "\n",
        "  print(yt_link)\n",
        "  print()\n",
        "\n",
        "  # writing info in csv file:\n",
        "  csv_writer.writerow([headline, summary, yt_link])\n",
        "\n",
        "csv_file.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python Tutorial: Zip Files – Creating and Extracting Zip Archives\n",
            "In this video, we will be learning how to create and extract zip archives. We will start by using the zipfile module, and then we will see how to do this using the shutil module. We will learn how to do this with single files and directories, as well as learning how to use gzip as well. Let’s get started…\n",
            "https://youtube.com/watch?v=z0gguhEmWiY\n",
            "\n",
            "Python Data Science Tutorial: Analyzing the 2019 Stack Overflow Developer Survey\n",
            "In this Python Programming video, we will be learning how to download and analyze real-world data from the 2019 Stack Overflow Developer Survey. This is terrific practice for anyone getting into the data science field. We will learn different ways to analyze this data and also some best practices. Let’s get started…\n",
            "https://youtube.com/watch?v=_P7X8tMplsw\n",
            "\n",
            "Python Multiprocessing Tutorial: Run Code in Parallel Using the Multiprocessing Module\n",
            "In this Python Programming video, we will be learning how to run code in parallel using the multiprocessing module. We will also look at how to process multiple high-resolution images at the same time using a ProcessPoolExecutor from the concurrent.futures module. Let’s get started…\n",
            "https://youtube.com/watch?v=fKl2JW_qrso\n",
            "\n",
            "Python Threading Tutorial: Run Code Concurrently Using the Threading Module\n",
            "In this Python Programming video, we will be learning how to run threads concurrently using the threading module. We will also look at how to download multiple high-resolution images online using a ThreadPoolExecutor from the concurrent.futures module. Let’s get started…\n",
            "https://youtube.com/watch?v=IEEhzQoKtQU\n",
            "\n",
            "Update (2019-09-03)\n",
            "Hey everyone. I wanted to give you an update on my videos. I will be releasing videos on threading and multiprocessing within the next week. Thanks so much for your patience. I currently have a temporary recording studio setup at my Airbnb that will allow me to record and edit the threading/multiprocessing videos. I am going to be moving into my new house in 10 days and once I have my recording studio setup then you can expect much faster video releases. I really appreciate how patient everyone has been while I go through this move, especially those of you who are contributing monthly through YouTube \n",
            "None\n",
            "\n",
            "Python Quick Tip: The Difference Between “==” and “is” (Equality vs Identity)\n",
            "In this Python Programming Tutorial, we will be learning the difference between using “==” and the “is” keyword when doing comparisons. The difference between these is that “==” checks to see if values are equal, and the “is” keyword checks their identity, which means it’s going to check if the values are identical in terms of being the same object in memory. We’ll learn more in the video. Let’s get started…\n",
            "https://youtube.com/watch?v=mO_dS3rXDIs\n",
            "\n",
            "Python Tutorial: Calling External Commands Using the Subprocess Module\n",
            "In this Python Programming Tutorial, we will be learning how to run external commands using the subprocess module from the standard library. We will learn how to run commands, capture the output, handle errors, and also how to pipe output into other commands. Let’s get started…\n",
            "https://youtube.com/watch?v=2Fp1N6dof0Y\n",
            "\n",
            "Visual Studio Code (Windows) – Setting up a Python Development Environment and Complete Overview\n",
            "In this Python Programming Tutorial, we will be learning how to set up a Python development environment in VSCode on Windows. VSCode is a very nice free editor for writing Python applications and many developers are now switching over to this editor. In this video, we will learn how to install VSCode, get the Python extension installed, how to change Python interpreters, create virtual environments, format/lint our code, how to use Git within VSCode, how to debug our programs, how unit testing works, and more. We have a lot to cover, so let’s go ahead and get started…\n",
            "https://youtube.com/watch?v=-nh9rCzPJ20\n",
            "\n",
            "Visual Studio Code (Mac) – Setting up a Python Development Environment and Complete Overview\n",
            "In this Python Programming Tutorial, we will be learning how to set up a Python development environment in VSCode on MacOS. VSCode is a very nice free editor for writing Python applications and many developers are now switching over to this editor. In this video, we will learn how to install VSCode, get the Python extension installed, how to change Python interpreters, create virtual environments, format/lint our code, how to use Git within VSCode, how to debug our programs, how unit testing works, and more. We have a lot to cover, so let’s go ahead and get started…\n",
            "https://youtube.com/watch?v=06I63_p-2A4\n",
            "\n",
            "Clarifying the Issues with Mutable Default Arguments\n",
            "In this Python Programming Tutorial, we will be clarifying the issues with mutable default arguments. We discussed this in my last video titled “5 Common Python Mistakes and How to Fix Them”, but I received many comments from people who were still confused. So we will be doing a deeper dive to explain exactly what is going on here. Let’s get started…\n",
            "https://youtube.com/watch?v=_JGmemuINww\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQgpFaKBBOQv"
      },
      "source": [
        "Sometimes we'll run into situation when we're missing some data. If that happens, it could break our scraper (like above).\n",
        "\n",
        " Maybe we're pulling down a list of items and one is missing an image or link or something. \n",
        "\n",
        "In this case we can put that part of code in try/except block."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--scotxDSdSe"
      },
      "source": [
        "Now that we have scraped our information, we can save this in a file. Let's save this information to a csv file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW_MuZTB9-Eh"
      },
      "source": [
        "import csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qykEb8JOSs5o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "24dc6c6f-b827-4182-d6ed-228d4155fc0a"
      },
      "source": [
        "csv_file = open('cms_scrape.csv', 'w')\n",
        "\n",
        "csv_writer = csv.writer(csv_file)\n",
        "csv_writer.writerow(['headline', 'summary', 'video_link'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_gO5CgEYdFa"
      },
      "source": [
        "If we want to scrape data from larger websites like Facebook or Twitter, we can go through their public API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTZ3rTiBUnt3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}